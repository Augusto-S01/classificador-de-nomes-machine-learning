{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f5c5c1b0-e33f-4353-90e0-2217354f0eda",
   "metadata": {},
   "source": [
    "# 1. Importação das bibliotecas "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be9d544e-2ca9-4e7d-a839-8405633a8e1e",
   "metadata": {},
   "source": [
    "Aqui é feito a importação de todos os pacotes que serão utilizado nos estudos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61cfb92a-7104-43c0-a35e-f0d3474cf816",
   "metadata": {
    "jupyter": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import string\n",
    "import unicodedata\n",
    "import json\n",
    "import multiprocessing\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import StandardScaler,LabelEncoder\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier , StackingClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold , RandomizedSearchCV , GridSearchCV , cross_val_score, KFold\n",
    "from sklearn.metrics import classification_report, accuracy_score , make_scorer, r2_score , f1_score , confusion_matrix\n",
    "from scipy.stats import randint, uniform\n",
    "from joblib import dump, load\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.cluster import DBSCAN\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.cluster import AgglomerativeClustering\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from tensorflow.keras.models import Sequential , clone_model , load_model\n",
    "from tensorflow.keras.layers import Dense, Dropout\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b92ddbf3-1b9d-4b6b-8300-a8e4aed7d3df",
   "metadata": {},
   "source": [
    "# 2.  Configuração das bibliotecas"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a63dc93-2219-4b22-9c0b-c7a67e2d31e0",
   "metadata": {},
   "source": [
    "essa linha abaixo serve para resetar a largura das colunas na hora de exibir, em alguns cenarios estava tendo bug e tive que usar isso para adaptar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b6a5587-bfc2-46b2-aeba-67a539787da0",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.reset_option('display.max_colwidth')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43c2944c-387d-42cd-879c-9b649717bb6e",
   "metadata": {},
   "source": [
    "# 3. importação dos CSV e transformando em datasets pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "694a31b9-cf8b-4779-86a0-7214497fcea2",
   "metadata": {},
   "outputs": [],
   "source": [
    "gruposDFnomeDasColunas = [\n",
    "    \"nome\",\n",
    "    \"classificacao\",\n",
    "    \"frequencia_feminina\",\n",
    "    \"frequencia_masculina\",\n",
    "    \"frequencia_total\",\n",
    "    \"proporcao\",\n",
    "    \"nomes_alternativos\"    \n",
    "]\n",
    "gruposDF = pd.read_csv('../data/grupos.csv', names=gruposDFnomeDasColunas, header=0)\n",
    "gruposDF.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4311259d-c2e3-4bfd-ac29-00f04fe50ce4",
   "metadata": {},
   "outputs": [],
   "source": [
    "nomesDSnomeDasColunas = [\n",
    "    \"nomes_alternativos\",\n",
    "    \"classificacao\",\n",
    "    \"primeiro_nome\",\n",
    "    \"frequencia_feminina\",\n",
    "    \"frequencia_masculina\",\n",
    "    \"frequencia_total\",\n",
    "    \"frequencia_grupo\",\n",
    "    \"nome_grupo\",\n",
    "    \"proporcao\"\n",
    "]\n",
    "nomesDF= pd.read_csv(\"../data/nomes.csv\", names=nomesDSnomeDasColunas, header=0)\n",
    "nomesDF.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db89b11d-4a0e-4923-bbee-080dd7fed19c",
   "metadata": {},
   "source": [
    "# 4. Limpeza de nulos e n/a"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5a55d09-ff97-4c6f-8436-25dc87667131",
   "metadata": {},
   "source": [
    "nas limpezas dos dados nulos, foram verificados que os dados \"NAN\" na verdade, são dados que vazios, pois por exemplo, na linha AALINE, temos a frequencia_feminina de 66 e  frequencia_total de 66 também, então sobraria 0 para a frequencia_masculina"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d877fbd4-ebfe-46a5-8a54-d1c7bc58d696",
   "metadata": {},
   "outputs": [],
   "source": [
    "gruposDF.fillna(0, inplace=True)\n",
    "nomesDF.fillna(0, inplace=True)\n",
    "\n",
    "gruposDF.drop_duplicates(inplace=True)\n",
    "nomesDF.drop_duplicates(inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19bca73a-65f3-4b2a-b38a-b4357527bd88",
   "metadata": {},
   "source": [
    "# 5. Criando novos dados "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "110b091d-237c-42cd-821e-dd3d64ef003b",
   "metadata": {},
   "source": [
    "## 5.1 Porcentagem de cada classe\n",
    "para melhor visualização da frequencia, é necessario a criação dos dados de porcentagem "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37fa7556-1a5c-4a12-98a2-995152ae520d",
   "metadata": {},
   "outputs": [],
   "source": [
    "gruposDF.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5192c615-99bd-4241-b5d9-e81f808534ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# gruposDF.drop(columns=[\"nomes_alternativos\"],inplace=True)\n",
    "# nomesDF.drop(columns=[\"nomes_alternativos\",\"frequencia_grupo\",\"nome_grupo\"],inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9076d3ec-cc8f-49f7-9593-893ee99373c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "gruposDF[\"porcentagem_feminina\"]  = 0\n",
    "gruposDF[\"porcentagem_masculina\"] = 0\n",
    "nomesDF[\"porcentagem_feminina\"] = 0\n",
    "nomesDF[\"porcentagem_masculina\"] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a8621eb-b4a6-4d3a-bee3-29794ca94183",
   "metadata": {},
   "outputs": [],
   "source": [
    "nomesDF.rename(columns=\n",
    "               {\"primeiro_nome\": \"nome\"}\n",
    "               ,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e6c6580-5ef9-4b16-a8c6-4dd76608a2f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "gruposDF[\"porcentagem_masculina\"] = round(gruposDF[\"frequencia_masculina\"] / gruposDF[\"frequencia_total\"], 7)\n",
    "gruposDF[\"porcentagem_feminina\"] =  round(gruposDF[\"frequencia_feminina\"]  / gruposDF[\"frequencia_total\"], 7)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ead5f1a-fd7c-47f0-a786-4fabf8e20234",
   "metadata": {},
   "outputs": [],
   "source": [
    "gruposDF.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8de4fce4-4697-47df-8b62-a03762207090",
   "metadata": {},
   "outputs": [],
   "source": [
    "nomesDF[\"porcentagem_masculina\"] = round(nomesDF[\"frequencia_masculina\"] / nomesDF[\"frequencia_total\"], 7)\n",
    "nomesDF[\"porcentagem_feminina\"] = round(nomesDF[\"frequencia_feminina\"] / nomesDF[\"frequencia_total\"], 7)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "510680ba-d8d6-419f-9e28-dffa3a300735",
   "metadata": {},
   "outputs": [],
   "source": [
    "nomesDF[(nomesDF[\"porcentagem_feminina\"] == 0) & (nomesDF[\"porcentagem_masculina\"] == 0)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1f5dce9-1020-4db3-977a-55f5d5c63e84",
   "metadata": {},
   "outputs": [],
   "source": [
    "gruposDF[(gruposDF[\"porcentagem_feminina\"] == 0) & (gruposDF[\"porcentagem_masculina\"] == 0)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd7055a1-02ab-4f6e-a59c-71251cc0458d",
   "metadata": {},
   "outputs": [],
   "source": [
    "nomesDF.set_index('nome', inplace=True)\n",
    "gruposDF.set_index('nome', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94d5daf3-7f5e-412f-a2e1-9932e7aae079",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = gruposDF.combine_first(nomesDF).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "860c35c4-15cc-4af0-a9c1-74a0a7f26749",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9adcf6ac-8a38-4b0a-ad7a-dbcdab460a82",
   "metadata": {},
   "source": [
    "## 5.2 Criando colunas binarias\n",
    "\n",
    "Para alimentar os modelos, foi pensado a estrategia de criar colunas binarias para cada posição do nome , por exemplo, \n",
    "\n",
    "a letra 1 ( primeira letra) é igual a A ? ou seja , a coluna LETRA_1_A , e assim por diante \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79e581f4-7af9-4c36-8d3f-5f224488eb82",
   "metadata": {},
   "outputs": [],
   "source": [
    "def processar_dataset(data, max_posicoes=20):\n",
    "    alfabeto = string.ascii_uppercase\n",
    "    novas_colunas = [f\"LETRA_{i}_{letra}\" for i in range(1, max_posicoes + 1) for letra in alfabeto]\n",
    "    novas_colunas_df = pd.DataFrame(0, index=data.index, columns=novas_colunas)\n",
    "    data = pd.concat([data, novas_colunas_df], axis=1)\n",
    "    for index, row in data.iterrows():\n",
    "        nome = row['nome'].upper()\n",
    "        for posicao, letra in enumerate(nome):\n",
    "            if posicao < max_posicoes and letra in alfabeto:\n",
    "                coluna = f\"LETRA_{posicao + 1}_{letra}\"\n",
    "                if coluna in data.columns:\n",
    "                    data.at[index, coluna] = 1\n",
    "\n",
    "    return data\n",
    "data = processar_dataset(data)\n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "696fe887",
   "metadata": {},
   "source": [
    "## 6. Criando e executando label encoder\n",
    "o label Encoder faz a função de codificador , para transformar os dados qualitativos em numeros, para assim que a maquina prever , o label encoder poder utilizar a função de inverse transform e trazer a real classe da previsão "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8985237d-4f45-457c-a2dc-3fe261a4b9c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "le = LabelEncoder()\n",
    "le = le.fit(data['classificacao'])\n",
    "data['classificacao'] = le.fit_transform(data['classificacao'])\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d627789b-ba17-47b3-a45f-2db7a9d4e45c",
   "metadata": {},
   "source": [
    "# separando dados de treino e teste\n",
    "separa as colunas de input e a coluna de target (Classificacao) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a923ebca-df92-4542-a469-dbf80e158602",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data.drop(columns=[\"nome\",\t'frequencia_grupo','nome_grupo','nomes_alternativos',\"classificacao\"\t,\"frequencia_feminina\",\t\"frequencia_masculina\"\t,\"frequencia_total\"\t,\"proporcao\"\t,\"porcentagem_feminina\"\t,\"porcentagem_masculina\"])\n",
    "y = data['classificacao']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b927a6d-3246-45b3-af0a-74cf2a1eb474",
   "metadata": {},
   "source": [
    "# 7. Criando Funções Auxiliares"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68df1b26",
   "metadata": {},
   "source": [
    "## 7.1 Criando função de input de dados\n",
    "a função de input de dados recebe um nome, e tranforma em colunas binarias, assim como os dados de treino, para encaixar com o shape dos dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9345ac28-f4fc-40eb-a7e6-b0a0ff570321",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preparar_input_para_modelo(nome, max_posicoes=20):\n",
    "    nome = nome.upper()\n",
    "    alfabeto = string.ascii_uppercase\n",
    "    input_vector = np.zeros(max_posicoes * len(alfabeto), dtype=int)\n",
    "    for posicao, letra in enumerate(nome):\n",
    "        if posicao < max_posicoes and letra in alfabeto:\n",
    "            indice_letra = alfabeto.index(letra)\n",
    "            indice_vetor = posicao * len(alfabeto) + indice_letra\n",
    "            input_vector[indice_vetor] = 1\n",
    "\n",
    "    \n",
    "    return input_vector.reshape(1, -1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffc9ea32-429e-4c49-bc8a-cc6a2f8f7d15",
   "metadata": {},
   "source": [
    "## 7.2 Criando Função para plotar Matriz de Confusão \n",
    "\n",
    "essa vai ser uma função auxiliar que vai nos ajudar a evitar repetição de codigo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12d80380-9959-4fe8-8503-1735d8ede6e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plotar_matriz_confusao(cm, classes=['F', 'M'], title='Matriz de Confusão', cmap='Blues'):\n",
    "    plt.figure(figsize=(10, 7))\n",
    "    ax = sns.heatmap(cm, annot=False, fmt='d', cmap=cmap, xticklabels=classes, yticklabels=classes, cbar=False)\n",
    "    \n",
    "    # Adicionar anotações de TP, FP, FN, TN\n",
    "    for i in range(cm.shape[0]):\n",
    "        for j in range(cm.shape[1]):\n",
    "            if i == j:\n",
    "                annotation = f'{cm[i, j]} (TP)'  # Verdadeiro Positivo\n",
    "            elif i > j:\n",
    "                annotation = f'{cm[i, j]} (FN)'  # Falso Negativo\n",
    "            else:\n",
    "                annotation = f'{cm[i, j]} (FP)'  # Falso Positivo\n",
    "            ax.text(j + 0.5, i + 0.5, annotation, color='black', ha='center', va='center')\n",
    "\n",
    "    plt.xlabel('Previsto')\n",
    "    plt.ylabel('Valor Real')\n",
    "    plt.title(title)\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "475356e0-214b-431e-b4eb-f08ded6e339b",
   "metadata": {},
   "source": [
    "## 7.3 Criando Função Auxiliar  para criar diretorios dinamicos \n",
    "\n",
    "isso ajudara a organizar as pastas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78243750-811a-47bc-9cb0-8127f5c245c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def criar_diretorio(caminho):\n",
    "    if not os.path.exists(caminho):\n",
    "        os.makedirs(caminho)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "032ae350-1691-45a0-828a-028af307e791",
   "metadata": {},
   "source": [
    "## 7.4 Criando Objeto Auxiliar para manter todos os modelos \n",
    "\n",
    "esse objeto servirar para manter todos os modelos salvos em um lugar para testar de forma manual futuramente "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12757841-c3ff-4923-b6c6-4c2c92e346ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "modelos = {}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0299b7a4-c95c-4f64-8eb5-a2010f5bad5d",
   "metadata": {},
   "source": [
    "## 7.5 Criação Função Auxiliar para gerar relatorios de classificação\n",
    "essa função auxiliar ajuda a evitar repetição de codigo toda vez que for gerar um relatorio de classificação"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f17fb809-4f3d-489d-a8c5-b61ce5dd1f73",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gerar_relatorio_classificacao(Y_teste, previsoes, le=le):\n",
    "    Y_teste_decodificado = le.inverse_transform(Y_teste)\n",
    "    previsoes_decodificadas = le.inverse_transform(previsoes)\n",
    "    class_report = classification_report(Y_teste_decodificado, previsoes_decodificadas,output_dict=True)\n",
    "    print(class_report)\n",
    "    print(f'Acuracia {class_report[\"accuracy\"]}')\n",
    "    return class_report, Y_teste_decodificado, previsoes_decodificadas\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f895538-a93f-4ef4-a252-f681301ffd8d",
   "metadata": {},
   "source": [
    "## 7.6 Criação de função para treinar|Carregar modelos \"simples\"\n",
    "essa é a principal das funções auxiliares, ela é responsavel por treinar ou carregar os dados dos modelos do scikit learn e consumir as outras funções auxiliares para trazer os dados "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bdf6bad-02be-45db-a980-2fb0076f0211",
   "metadata": {},
   "outputs": [],
   "source": [
    "def treinar_e_avaliar_modelo(modelo, X, y, model_name, classes=['F', 'M'],modelos=modelos):\n",
    "    base_path = f'../modelos_e_resultados/{model_name}/'\n",
    "    model_path = os.path.join(base_path, 'modelo.joblib')\n",
    "    results_path = os.path.join(base_path, 'resultados.json')\n",
    "    \n",
    "    # Criar diretório para o modelo se não existir\n",
    "    criar_diretorio(base_path)\n",
    "    \n",
    "    if os.path.exists(model_path) and os.path.exists(results_path):\n",
    "        # Carregar modelo e resultados\n",
    "        modelo = load(model_path)\n",
    "        with open(results_path, 'r') as f:\n",
    "            resultados = json.load(f)\n",
    "        \n",
    "        # Exibir os resultados carregados\n",
    "        print(f\"Resultados carregados:\")\n",
    "        print(f\"F1-scores de cada fold: {resultados['f1_scores']}\")\n",
    "        print(f\"Média do F1-score: {resultados['media_f1_score']}\")\n",
    "        print(\"Classification Report:\")\n",
    "        print(resultados['classification_report'])\n",
    "        \n",
    "        # Exibir a matriz de confusão carregada\n",
    "        cm = np.array(resultados['confusion_matrix'])\n",
    "        plotar_matriz_confusao(cm, classes=classes)\n",
    "    else:\n",
    "        # Treinar o modelo e calcular os resultados\n",
    "        X_treino, X_teste, Y_treino, Y_teste = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
    "        \n",
    "        kf = StratifiedKFold(n_splits=10, shuffle=True, random_state=42)\n",
    "        f1_scorer = make_scorer(f1_score, average='macro')\n",
    "        f1_scores = cross_val_score(modelo, X_treino, Y_treino, cv=kf, scoring=f1_scorer)\n",
    "        \n",
    "        print(f'F1-scores de cada fold: {f1_scores}')\n",
    "        print(f'Média do F1-score: {f1_scores.mean()}')\n",
    "        \n",
    "        \n",
    "        modelo.fit(X_treino, Y_treino)\n",
    "        dump(modelo, model_path)\n",
    "        \n",
    "        previsoes = modelo.predict(X_teste)\n",
    "        acc = accuracy_score(Y_teste, previsoes)\n",
    "        print(f'{model_name} - Acurácia: {acc}')\n",
    "        \n",
    "   \n",
    "        class_report, Y_teste_decodificado, previsoes_decodificadas = gerar_relatorio_classificacao(Y_teste, previsoes, le)\n",
    "        \n",
    "    \n",
    "        cm = confusion_matrix(Y_teste_decodificado, previsoes_decodificadas)\n",
    "        plotar_matriz_confusao(cm, classes=classes)\n",
    "        modelos[model_name] = modelo\n",
    "   \n",
    "        resultados = {\n",
    "            \"f1_scores\": f1_scores.tolist(),\n",
    "            \"media_f1_score\": f1_scores.mean(),\n",
    "            \"classification_report\": class_report,\n",
    "            \"confusion_matrix\": cm.tolist()\n",
    "        }\n",
    "        with open(results_path, 'w') as f:\n",
    "            json.dump(resultados, f)\n",
    "    \n",
    "    return modelo"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5434cdeb-ab9f-4d1b-ac60-d54280f25400",
   "metadata": {},
   "source": [
    "## 7.8 Criação da função auxiliar para remover acentos de nomes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0b08032-e4d4-45f5-a16e-e49345a76a0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_acentos(string):\n",
    "    nfkd = unicodedata.normalize('NFKD', string)\n",
    "    return \"\".join(c for c in nfkd if not unicodedata.combining(c))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc832fed-56fe-415c-bcc0-740abc763451",
   "metadata": {},
   "source": [
    "## 7.9 Criação da função Auxiliar para buscar nome no dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ece7a708-2161-48bd-95f0-1394ef52bea4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def busca_no_dataframe(nome):\n",
    "    nome = nome.upper()\n",
    "    if nome in data['nome'].values:        \n",
    "        copyDT = data.loc[data['nome'] == nome, [\n",
    "            'nome', 'classificacao', 'frequencia_feminina', 'nome_grupo',\n",
    "            'frequencia_masculina', 'frequencia_total',\n",
    "            'proporcao', 'porcentagem_feminina',\n",
    "            'porcentagem_masculina', 'nomes_alternativos'  # Incluindo a nova coluna\n",
    "        ]].copy()\n",
    "\n",
    "        \n",
    "        retornoDataFrame = copyDT.to_dict(orient='records')[0] \n",
    "        \n",
    "\n",
    "        if 'nomes_alternativos' in retornoDataFrame and pd.notna(retornoDataFrame['nomes_alternativos']):\n",
    "            retornoDataFrame['nomes_alternativos'] = retornoDataFrame['nomes_alternativos'].split('|')\n",
    "        else:\n",
    "            retornoDataFrame['nomes_alternativos'] = []  \n",
    "        \n",
    "\n",
    "        retornoDataFrame['status'] = '200'\n",
    "        retornoDataFrame['classificacao'] = le.inverse_transform([retornoDataFrame['classificacao']])[0]\n",
    "\n",
    "        return retornoDataFrame \n",
    "    else:\n",
    "        return {\"status\": \"400\"}\n",
    "\n",
    "\n",
    "resultado = busca_no_dataframe('augusto')\n",
    "print(resultado)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59709157-2aba-43d7-95df-dbd50a77626b",
   "metadata": {},
   "outputs": [],
   "source": [
    "data['nomes_alternativos']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d6fe6b7-643e-4478-96de-dcff95be39cc",
   "metadata": {},
   "source": [
    "## 7.10  Criando função auxiliar para desconverter de classeEncode para classeOriginal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fa1bbd6-f49c-4c70-b8d8-08b4275dd93d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def desconverteEncoding(resultado, le=le):\n",
    "    return le.inverse_transform([resultado])[0]\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "574540d5-4061-4dae-916e-bd4fc6e329b4",
   "metadata": {},
   "source": [
    "- - - "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb3044a5",
   "metadata": {},
   "source": [
    "# 8. Regressão Logistica"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16f2a43b-a7f8-4b13-837f-6debb16d51ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "log_reg = LogisticRegression(max_iter=1000)\n",
    "log_reg = treinar_e_avaliar_modelo(log_reg, X, y, \"regressao_logistica\")\n",
    "modelos[\"regressao_logistica\"] = log_reg\n",
    "log_reg\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50cbedbd-92e1-430f-bba3-a1aae3cf62b0",
   "metadata": {},
   "source": [
    "Com o modelo de regressao logistica foi obtido o resultado medio de F1-score de ~0.85, que significa que temos um um desempenho constante mesmo com diferentes conjuntos de dados . \n",
    "\n",
    "Já o classification_report nos da a informação que a precisão para ambas as classes é de 0.87, o que é um otimo sinal que não há um overfit pois é um valor bem proximo do F1 score\n",
    "\n",
    "a matriz de confusão também revela que há valores muito baixo de Falso Negativos e Falso Positivos comparados ao Verdadeiro Positivo e ao Verdadeiro Negativo"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc43ffd4-8039-4b31-9629-573566335675",
   "metadata": {},
   "source": [
    "# 9. KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b49e8d8-be56-4306-a830-5337f1f76ec5",
   "metadata": {},
   "outputs": [],
   "source": [
    "knn = KNeighborsClassifier(n_neighbors=5)\n",
    "knn = treinar_e_avaliar_modelo(knn, X, y, \"knn\")\n",
    "modelos['knn'] = knn\n",
    "knn"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5765226-027d-43ba-a9b1-4b263a310df4",
   "metadata": {},
   "source": [
    "No resultado do knn vemos que o f1 score dele foi um pouco maior que o anterior (regressao logistica ) porem os falsos positivos e falsos negativos foram bem maiores "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88e063f5-4bb1-4acc-b844-57bf9511c50a",
   "metadata": {},
   "source": [
    "# 10. Naive bayes | GaussianNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78e19147-7bcd-489c-8528-cfd4f52dcc95",
   "metadata": {},
   "outputs": [],
   "source": [
    "naive_bayes = GaussianNB()\n",
    "naive_bayes = treinar_e_avaliar_modelo(naive_bayes, X, y, \"naive_bayes\")\n",
    "modelos['naive_bayes'] = naive_bayes\n",
    "naive_bayes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f33b9c0-1d6d-47ff-971c-871f2e067b06",
   "metadata": {},
   "source": [
    "o Modelo de naive bayes foi bem inferior em questão do F1-Score em relação aos dois ultimos modelos  e tivemos um crescente muito grande em questão de falsos negativos"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23c09aef",
   "metadata": {},
   "source": [
    "# 11. Random forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37ef2cb5-586b-4e36-bb04-3b2cea7ea91a",
   "metadata": {},
   "outputs": [],
   "source": [
    "random_forest = RandomForestClassifier(max_depth=None, n_estimators=100, random_state=42)\n",
    "random_forest = treinar_e_avaliar_modelo(random_forest, X, y, \"random_forest\")\n",
    "modelos['random_forest'] = random_forest\n",
    "random_forest"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41681e93-db35-47d1-83d9-eac593fecb2b",
   "metadata": {},
   "source": [
    "o modelo de random forest foi o melhor de de F1-score até agora, e obteve um falso negativo baixo , e obtemos valores medianos bem baixo tambem de falso postivo"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3a39a21",
   "metadata": {},
   "source": [
    "# 12. rede neural"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de22871f-75ae-48cf-ac7b-173a4aa7c7cd",
   "metadata": {},
   "source": [
    "## 12.1 Criando função especifica para o tensorflow/keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11a9bcaf-9752-405f-880e-a3f96ac582ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "def criar_modelo_neural(input_dim):\n",
    "    modelo = Sequential([\n",
    "        Dense(160, input_dim=input_dim, activation='relu'), \n",
    "        Dropout(0.2),\n",
    "        Dense(80, activation='relu'), \n",
    "        Dropout(0.2),\n",
    "        Dense(1, activation='sigmoid')\n",
    "    ])\n",
    "    modelo.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "    return modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08762af8-a8e3-47ab-82aa-299275226e34",
   "metadata": {},
   "outputs": [],
   "source": [
    "def treinar_e_avaliar_modelo_keras(modelo, X, y, model_name, classes=['F', 'M'], epochs=50, batch_size=32, n_splits=5):\n",
    "\n",
    "    if isinstance(X, pd.DataFrame):\n",
    "        X = X.values\n",
    "    if isinstance(y, pd.Series):\n",
    "        y = y.values\n",
    "\n",
    "    X = np.array(X)\n",
    "    y = np.array(y)\n",
    "\n",
    "\n",
    "    base_path = f'../modelos_e_resultados/{model_name}/'\n",
    "    model_path = os.path.join(base_path, 'modelo.h5')\n",
    "    results_path = os.path.join(base_path, 'resultados.json')\n",
    "\n",
    "  \n",
    "    os.makedirs(base_path, exist_ok=True)\n",
    "\n",
    "    if os.path.exists(model_path) and os.path.exists(results_path):\n",
    "      \n",
    "        modelo = load_model(model_path)\n",
    "        with open(results_path, 'r') as f:\n",
    "            resultados = json.load(f)\n",
    "\n",
    "        print(\"Resultados carregados:\")\n",
    "        print(f\"Acurácias de cada fold: {resultados['accuracies']}\")\n",
    "        print(f\"Média da Acurácia: {resultados['media_accuracia']}\")\n",
    "        print(\"Classification Report:\")\n",
    "        print(resultados['classification_report'])\n",
    "\n",
    "      \n",
    "        cm = np.array(resultados['confusion_matrix'])\n",
    "        plotar_matriz_confusao(cm, classes=classes)\n",
    "    else:\n",
    "    \n",
    "        kf = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=42)\n",
    "\n",
    "  \n",
    "        historicos = []\n",
    "        accuracies = []\n",
    "        melhor_acuracia = 0\n",
    "        melhor_modelo = None\n",
    "\n",
    "     \n",
    "        for fold, (train_index, val_index) in enumerate(kf.split(X, y), 1):\n",
    "            print(f\"\\nTreinando fold {fold}\")\n",
    "\n",
    "            \n",
    "            X_train, X_val = X[train_index], X[val_index]\n",
    "            y_train, y_val = y[train_index], y[val_index]\n",
    "\n",
    "           \n",
    "            model_clone = clone_model(modelo)\n",
    "            model_clone.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "\n",
    "            history = model_clone.fit(X_train, y_train,\n",
    "                                      validation_data=(X_val, y_val),\n",
    "                                      epochs=epochs,\n",
    "                                      batch_size=batch_size,\n",
    "                                      verbose=1)\n",
    "\n",
    "       \n",
    "            _, accuracy = model_clone.evaluate(X_val, y_val, verbose=0)\n",
    "            accuracies.append(accuracy)\n",
    "            historicos.append(history.history)\n",
    "\n",
    "            print(f\"Acurácia do fold {fold}: {accuracy}\")\n",
    "\n",
    "      \n",
    "            if accuracy > melhor_acuracia:\n",
    "                melhor_acuracia = accuracy\n",
    "                melhor_modelo = model_clone\n",
    "\n",
    "\n",
    "        melhor_modelo.save(model_path)\n",
    "\n",
    "\n",
    "        y_pred = melhor_modelo.predict(X)\n",
    "        y_pred_classes = (y_pred > 0.5).astype(int).flatten()\n",
    "\n",
    "\n",
    "        class_report = classification_report(y, y_pred_classes, target_names=classes)\n",
    "        cm = confusion_matrix(y, y_pred_classes)\n",
    "\n",
    "\n",
    "        plotar_matriz_confusao(cm, classes=classes)\n",
    "\n",
    "\n",
    "        resultados = {\n",
    "            \"accuracies\": accuracies,\n",
    "            \"media_accuracia\": np.mean(accuracies),\n",
    "            \"classification_report\": class_report,\n",
    "            \"confusion_matrix\": cm.tolist(),\n",
    "            \"historicos\": historicos\n",
    "        }\n",
    "\n",
    "        with open(results_path, 'w') as f:\n",
    "            json.dump(resultados, f)\n",
    "\n",
    "        print(\"\\nResultados finais:\")\n",
    "        print(f\"Acurácias de cada fold: {accuracies}\")\n",
    "        print(f\"Média da Acurácia: {np.mean(accuracies)}\")\n",
    "        print(\"\\nClassification Report:\")\n",
    "        print(class_report)\n",
    "\n",
    "        modelos[model_name] = modelo\n",
    "\n",
    "    return modelo\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e7f4574-77ed-4bd8-bbf5-985305a55b53",
   "metadata": {},
   "source": [
    "## 12.2 Modelo de rede neural"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38e68ccb-9216-4ab2-9502-82dc5c80efdb",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "rede = criar_modelo_neural(X.shape[1])\n",
    "rede.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "rede = treinar_e_avaliar_modelo_keras(rede,X,y,'rede_neural')\n",
    "modelos['rede_neural'] = rede"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cef66549-34d8-4bf9-88e1-6487ee71b4c5",
   "metadata": {},
   "source": [
    "nesse modelo utilizando rede neurais , é possivel ver que a acuracia media de cada fold é bme alta (95%) e que no melhor modelo chega a bater um f1-score de 0.99% , o numero de falsos positivos é maior que alguns modelos e tem o  menor nuemro de falso negativo até agora"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbd2567a-544c-431f-a913-81d9a9de833b",
   "metadata": {},
   "source": [
    "# 13. Algoritmos de conjunto"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca4b63b5-b1a2-457a-bfe2-5e9942545078",
   "metadata": {},
   "source": [
    "## 13.1  Bagging com rede neural"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1806fed3-fb48-4257-806f-ca7ae74132a4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def bagging_neural_network_kfold(X, y, model_name, classes=['F', 'M'], n_estimators=10, epochs=50, batch_size=32, n_splits=5):\n",
    "    base_path = f'../modelos_e_resultados/{model_name}/'\n",
    "    results_path = os.path.join(base_path, 'resultados.json')\n",
    "    \n",
    "    criar_diretorio(base_path)\n",
    "    \n",
    "    if isinstance(X, pd.DataFrame):\n",
    "        X = X.values\n",
    "    if isinstance(y, pd.Series):\n",
    "        y = y.values\n",
    "\n",
    "    X = np.array(X)\n",
    "    y = np.array(y)\n",
    "    \n",
    "    le = LabelEncoder()\n",
    "    y_encoded = le.fit_transform(y)\n",
    "    \n",
    "    kf = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=42)\n",
    "    \n",
    "    accuracies = []\n",
    "    f1_scores = []\n",
    "    all_y_true = []\n",
    "    all_y_pred = []\n",
    "    modelos_bagging = []\n",
    "\n",
    "    for fold, (train_index, val_index) in enumerate(kf.split(X, y_encoded), 1):\n",
    "        print(f\"\\nProcessando fold {fold}/{n_splits}\")\n",
    "        \n",
    "        X_train, X_val = X[train_index], X[val_index]\n",
    "        y_train, y_val = y_encoded[train_index], y_encoded[val_index]\n",
    "        \n",
    "        best_acc = 0\n",
    "        best_f1 = 0\n",
    "        best_model_path = None\n",
    "        fold_models = []\n",
    "        \n",
    "        for i in range(n_estimators):\n",
    "            model_path = os.path.join(base_path, f'modelo_fold{fold}_estimador{i+1}.h5')\n",
    "            \n",
    "            if os.path.exists(model_path):\n",
    "                print(f\"Carregando modelo {i+1}/{n_estimators} do fold {fold} de: {model_path}\")\n",
    "                modelo = load_model(model_path)\n",
    "            else:\n",
    "                print(f\"Treinando modelo {i+1}/{n_estimators} no fold {fold}\")\n",
    "                indices = np.random.choice(X_train.shape[0], X_train.shape[0], replace=True)\n",
    "                X_bootstrap = X_train[indices]\n",
    "                y_bootstrap = y_train[indices]\n",
    "                \n",
    "                modelo = criar_modelo_neural(X.shape[1])\n",
    "                modelo.fit(X_bootstrap, y_bootstrap, epochs=epochs, batch_size=batch_size, validation_split=0.2, verbose=0)\n",
    "                \n",
    "                modelo.save(model_path)\n",
    "                print(f\"Modelo salvo em: {model_path}\")\n",
    "            \n",
    "            previsoes = modelo.predict(X_val).flatten()\n",
    "            previsoes_finais = (previsoes > 0.5).astype(int)\n",
    "            \n",
    "            acc = accuracy_score(y_val, previsoes_finais)\n",
    "            f1 = f1_score(y_val, previsoes_finais, average='macro')\n",
    "\n",
    "            if f1 > best_f1:\n",
    "                best_acc = acc\n",
    "                best_f1 = f1\n",
    "                best_model_path = model_path\n",
    "            \n",
    "            fold_models.append(modelo)\n",
    "        \n",
    "        print(f\"Melhor modelo do fold {fold}: {best_model_path} com F1-score de {best_f1:.2f}\")\n",
    "        \n",
    "        best_model = load_model(best_model_path)\n",
    "        previsoes = best_model.predict(X_val).flatten()\n",
    "        previsoes_finais = (previsoes > 0.5).astype(int)\n",
    "        \n",
    "        accuracies.append(best_acc)\n",
    "        f1_scores.append(best_f1)\n",
    "        \n",
    "        all_y_true.extend(y_val)\n",
    "        all_y_pred.extend(previsoes_finais)\n",
    "        \n",
    "        print(f\"Acurácia do fold {fold}: {best_acc:.2f}\")\n",
    "        print(f\"F1-score do fold {fold}: {best_f1:.2f}\")\n",
    "        \n",
    "        modelos_bagging.extend(fold_models)\n",
    "    \n",
    "    class_report, all_y_true_decoded, all_y_pred_decoded = gerar_relatorio_classificacao(np.array(all_y_true), np.array(all_y_pred), le)\n",
    "    \n",
    "    cm = confusion_matrix(all_y_true_decoded, all_y_pred_decoded)\n",
    "    plotar_matriz_confusao(cm, classes=classes)\n",
    "    \n",
    "    resultados = {\n",
    "        \"accuracies\": accuracies,\n",
    "        \"media_accuracia\": np.mean(accuracies),\n",
    "        \"f1_scores\": f1_scores,\n",
    "        \"media_f1_score\": np.mean(f1_scores),\n",
    "        \"classification_report\": class_report,\n",
    "        \"confusion_matrix\": cm.tolist()\n",
    "    }\n",
    "    \n",
    "    with open(results_path, 'w') as f:\n",
    "        json.dump(resultados, f)\n",
    "    \n",
    "    print(\"\\nResultados finais:\")\n",
    "    print(f\"Acurácias de cada fold: {accuracies}\")\n",
    "    print(f\"Média da Acurácia: {np.mean(accuracies)}\")\n",
    "    print(f\"F1-scores de cada fold: {f1_scores}\")\n",
    "    print(f\"Média do F1-score: {np.mean(f1_scores)}\")\n",
    "    print(\"\\nClassification Report:\")\n",
    "    print(class_report)\n",
    "    \n",
    "    return modelos_bagging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92d01a54-5dbe-404b-a5f1-ec6137e668d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "modelos_bagging = bagging_neural_network_kfold(X, y, model_name='bagging_kfold', classes=['F', 'M'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52afac91-0d8a-4ef5-8e19-19e5cb55ab83",
   "metadata": {},
   "outputs": [],
   "source": [
    "def previsao_bagging(modelos, X):\n",
    "    if len(modelos) == 0:\n",
    "        raise ValueError(\"A lista de modelos está vazia. Certifique-se de que os modelos estão treinados e adicionados à lista.\")\n",
    "    \n",
    "    previsoes_agregadas = np.zeros(X.shape[0])\n",
    "    \n",
    "    for modelo in modelos:\n",
    "        previsoes = modelo.predict(X).flatten()\n",
    "        previsoes_agregadas += previsoes\n",
    "\n",
    "    previsoes_agregadas /= len(modelos)\n",
    "    \n",
    "    previsoes_finais = (previsoes_agregadas > 0.5).astype(int)\n",
    "    \n",
    "    return previsoes_finais"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ade6ec2-f75f-421d-8b69-f045dec67296",
   "metadata": {},
   "source": [
    "o modelo de baggins de rede neurais demonstra ter mais falsos positivos e negativos do que a propria rede neural isolada, porém apresenta um f1 score bom"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "220a2a31-c79a-4a98-aa8d-68d9fef0b8a2",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## 13.2 Boosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "402604b2-4e8b-4ba4-92f2-c406d16d4cb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1765c23-f14b-421a-9e97-f5ee030f1b13",
   "metadata": {},
   "outputs": [],
   "source": [
    "def treinar_e_avaliar_adaboost_logreg(X, y, model_name, classes=['F', 'M']):\n",
    "    base_path = f'../modelos_e_resultados/{model_name}/'\n",
    "    model_path = os.path.join(base_path, 'modelo_adaboost_logreg.joblib')\n",
    "    results_path = os.path.join(base_path, 'resultados.json')\n",
    "\n",
    "    criar_diretorio(base_path)\n",
    "\n",
    "    if os.path.exists(model_path) and os.path.exists(results_path):\n",
    "        adaboost_custom = load(model_path)\n",
    "        with open(results_path, 'r') as f:\n",
    "            resultados = json.load(f)\n",
    "\n",
    "\n",
    "        print(f\"Resultados carregados:\")\n",
    "        print(f\"Acurácia: {resultados['accuracy']:.2f}\")\n",
    "        print(resultados['classification_report'])\n",
    "\n",
    "\n",
    "        cm = np.array(resultados['confusion_matrix'])\n",
    "        plotar_matriz_confusao(cm, classes=classes)\n",
    "    else:\n",
    "\n",
    "        X = np.array(X)\n",
    "        y = np.array(y)\n",
    "\n",
    "\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "\n",
    "        estimator = LogisticRegression(max_iter=1000)\n",
    "\n",
    "\n",
    "        adaboost_custom = AdaBoostClassifier(estimator=estimator, n_estimators=50, random_state=42)\n",
    "\n",
    "\n",
    "        adaboost_custom.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "        y_pred = adaboost_custom.predict(X_test)\n",
    "\n",
    "\n",
    "        accuracy = accuracy_score(y_test, y_pred)\n",
    "        print(f\"Acurácia: {accuracy:.2f}\")\n",
    "\n",
    "        class_report = gerar_relatorio_classificacao(y_test, y_pred)\n",
    "\n",
    "\n",
    "        cm = confusion_matrix(y_test, y_pred)\n",
    "        plotar_matriz_confusao(cm, classes=classes)\n",
    "\n",
    "\n",
    "        dump(adaboost_custom, model_path)\n",
    "        print(f'class report type {type(class_report[1])}')\n",
    "    \n",
    "        resultados = {\n",
    "            \"accuracy\": accuracy,\n",
    "            \"classification_report\": class_report[0],\n",
    "            \"confusion_matrix\": cm.tolist()\n",
    "        }\n",
    "        with open(results_path, 'w') as f:\n",
    "            json.dump(resultados, f)\n",
    "\n",
    "    return adaboost_custom\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42ffe557-f61e-46f0-885c-6e3ad4352cb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "adaboost_model = treinar_e_avaliar_adaboost_logreg(X, y, 'boosting_log_reg')\n",
    "adaboost_model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "776b63fc-20a8-46dc-83ec-325cf7c61d89",
   "metadata": {},
   "source": [
    "o modelo de adaboost com regressao logistica apresentou uma acuracia relativamente baixa comparado aos outros modelos , valores altos de falso positivo e negativos , e um f1 score baixo também"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13eab388-c8d6-4c42-b3a8-127c5046dfda",
   "metadata": {},
   "source": [
    "## 13.4 Stacking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cbcc5b0-59d2-4563-b278-a3fc1dfe4b3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def treinar_e_avaliar_stacking(X, y, model_name, classes=['Class 0', 'Class 1']):\n",
    "    base_path = f'../modelos_e_resultados/{model_name}/'\n",
    "    model_path = os.path.join(base_path, 'modelo_stacking.joblib')\n",
    "    results_path = os.path.join(base_path, 'resultados.json')\n",
    "\n",
    "    criar_diretorio(base_path)\n",
    "\n",
    "    if os.path.exists(model_path) and os.path.exists(results_path):\n",
    "\n",
    "        stacking_model = load(model_path)\n",
    "        with open(results_path, 'r') as f:\n",
    "            resultados = json.load(f)\n",
    "\n",
    "\n",
    "        print(f\"Resultados carregados:\")\n",
    "        print(f\"Acurácia: {resultados['accuracy']:.2f}\")\n",
    "        print(resultados['classification_report'])\n",
    "\n",
    "\n",
    "        cm = np.array(resultados['confusion_matrix'])\n",
    "        plotar_matriz_confusao(cm, classes=classes)\n",
    "    else:\n",
    "\n",
    "        X = np.array(X)\n",
    "        y = np.array(y)\n",
    "\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    " \n",
    "        estimators = [\n",
    "            ('dt', DecisionTreeClassifier(max_depth=3)),\n",
    "            ('rf', RandomForestClassifier(n_estimators=100))\n",
    "        ]\n",
    "\n",
    "\n",
    "        meta_model = LogisticRegression(max_iter=1000)\n",
    "\n",
    "\n",
    "        stacking_model = StackingClassifier(estimators=estimators, final_estimator=meta_model)\n",
    "\n",
    "\n",
    "        stacking_model.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "        y_pred = stacking_model.predict(X_test)\n",
    "\n",
    "\n",
    "        accuracy = accuracy_score(y_test, y_pred)\n",
    "        print(f\"Acurácia: {accuracy:.2f}\")\n",
    "\n",
    "        class_report = gerar_relatorio_classificacao(y_test, y_pred)\n",
    "\n",
    "\n",
    "        cm = confusion_matrix(y_test, y_pred)\n",
    "        plotar_matriz_confusao(cm, classes=classes)\n",
    "\n",
    "        dump(stacking_model, model_path)\n",
    "\n",
    "        resultados = {\n",
    "            \"accuracy\": accuracy,\n",
    "            \"classification_report\": class_report[0],\n",
    "            \"confusion_matrix\": cm.tolist()\n",
    "        }\n",
    "        print(resultados)\n",
    "        with open(results_path, 'w') as f:\n",
    "            json.dump(resultados, f)\n",
    "\n",
    "    return stacking_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32364790-af2a-4a73-b428-82fa61173194",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "stacking_model = treinar_e_avaliar_stacking(X, y, 'stacking_model')\n",
    "stacking_model "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd8f5027-0946-41c0-884c-7b642416b417",
   "metadata": {},
   "source": [
    "o algoritmo de staciking de apresentou resultado semelhante ao de boosting, também com valores de acuracia e f1 baixos e classificações erradas "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93ead69b-f884-4874-8352-648666eccb6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preveEmTodosModelos(nome):\n",
    "    retorno = {}\n",
    "    \n",
    "    nome = remove_acentos(nome)\n",
    "    inputDados = preparar_input_para_modelo(nome)\n",
    "    print(\"Convertendo input de dados\")\n",
    "    print(inputDados)\n",
    "    print(inputDados.shape)\n",
    "    print(\"-------------------\")\n",
    "    \n",
    "    if not ('log_reg' in globals()):\n",
    "        raise ValueError(\"o modelo de regressão logistica não foi carregado.\")\n",
    "    else:\n",
    "        resultadoLogReg = desconverteEncoding(log_reg.predict(inputDados))\n",
    "        retorno['LogReg'] = resultadoLogReg\n",
    "        print(f'Resultado LogReg : {resultadoLogReg}')\n",
    "        print(\"--------------------------\")\n",
    "\n",
    "    if not ('knn' in globals()):\n",
    "        raise ValueError(\"o modelo de KNN não foi carregado.\")\n",
    "    else:\n",
    "        resultadoKnn = desconverteEncoding(knn.predict(inputDados))\n",
    "        retorno['knn'] = resultadoKnn\n",
    "        print(f'Resultado KNN : {resultadoKnn}')\n",
    "        print(\"--------------------------\")\n",
    "\n",
    "    if not ('naive_bayes' in globals()):\n",
    "        raise ValueError(\"o modelo de naive_bayes não foi carregado.\")\n",
    "    else:\n",
    "        resultadoNaive_bayes = desconverteEncoding(naive_bayes.predict(inputDados))\n",
    "        retorno['naive_bayes'] = resultadoNaive_bayes\n",
    "        print(f'Resultado naive_bayes : {resultadoNaive_bayes}')\n",
    "        print(\"--------------------------\")\n",
    "\n",
    "    if not ('random_forest' in globals()):\n",
    "        raise ValueError(\"o modelo de random_forest não foi carregado.\")\n",
    "    else:\n",
    "        resultadoRandom_forest = desconverteEncoding(random_forest.predict(inputDados))\n",
    "        retorno['random_forest'] = resultadoRandom_forest\n",
    "        print(f'Resultado random_forest : {resultadoRandom_forest}')\n",
    "        print(\"--------------------------\")\n",
    "\n",
    "    if not ('rede' in globals()):\n",
    "        raise ValueError(\"o modelo de redeNeural não foi carregado.\")\n",
    "    else:\n",
    "        resultadoRede = rede.predict(inputDados)\n",
    "        resultadoRede = desconverteEncoding(int(resultadoRede[0]))\n",
    "        retorno['rede_neural'] = resultadoRede\n",
    "        print(f'Resultado redeNeural {resultadoRede}')\n",
    "        print(\"--------------------------\")\n",
    "\n",
    "    if not ('modelos_bagging' in globals()):\n",
    "        raise ValueError(\"o modelo de baggin não foi carregado.\")\n",
    "    else:\n",
    "        print(f'modelos_bagging : {modelos_bagging}')\n",
    "        resultadoBagging = previsao_bagging(modelos_bagging, inputDados)\n",
    "        resultadoBagging = desconverteEncoding(resultadoBagging)\n",
    "        retorno['modelos_bagging'] = resultadoBagging\n",
    "        print(f'Resultado bagging {resultadoBagging}')\n",
    "        print(\"--------------------------\")\n",
    "\n",
    "    if not ('adaboost_model' in globals()):\n",
    "        raise ValueError(\"o modelo de adaboost_model não foi carregado.\")\n",
    "    else:\n",
    "        resultadoBoosting = desconverteEncoding(adaboost_model.predict(inputDados))\n",
    "        retorno['resultadoBoosting'] = resultadoBoosting\n",
    "        print(f'Resultado BoostingAda {resultadoBoosting}')\n",
    "        print(\"--------------------------\")\n",
    "\n",
    "    if not ('stacking_model' in globals()):\n",
    "        raise ValueError(\"o modelo de stacking_model não foi carregado.\")\n",
    "    else:\n",
    "        resultadoStacking = desconverteEncoding(stacking_model.predict(inputDados))\n",
    "        retorno['stacking_model'] = resultadoStacking\n",
    "        print(f'Resultado Stacking {resultadoStacking}')\n",
    "        print(\"--------------------------\")\n",
    "\n",
    "    if not ('data' in globals()):\n",
    "        raise ValueError(\"o dataframe nao foi carregado.\")\n",
    "    else:\n",
    "        resultadoDataFrame = busca_no_dataframe(nome)\n",
    "        retorno['data'] = resultadoDataFrame\n",
    "        print(f'Resultado Stacking {resultadoDataFrame}')\n",
    "        print(\"--------------------------\")\n",
    "\n",
    "    return retorno"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "277bf21e-4eb0-4094-9fbc-e189dca3a61f",
   "metadata": {},
   "outputs": [],
   "source": [
    "preveEmTodosModelos('ariel')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c93a86b-b4a9-497f-8fd2-9cb96d6cf1b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "diretorio='../modelos_e_resultados/'\n",
    "resultados_modelos = {}\n",
    "\n",
    "\n",
    "for nome_pasta in os.listdir(diretorio):\n",
    "    caminho_pasta = os.path.join(diretorio, nome_pasta)\n",
    "\n",
    "    # Verificar se é uma pasta\n",
    "    if os.path.isdir(caminho_pasta):\n",
    "        caminho_json = os.path.join(caminho_pasta, 'resultados.json')\n",
    "\n",
    "            # Verificar se o arquivo JSON existe\n",
    "        if os.path.exists(caminho_json):\n",
    "            with open(caminho_json, 'r') as arquivo:\n",
    "                resultados_modelos[nome_pasta] = json.load(arquivo)\n",
    "resultados = resultados_modelos\n",
    "for modelo, dados in resultados.items():\n",
    "    print(f\"Modelo: {modelo}\")\n",
    "    print(\"Dados carregados:\")\n",
    "    print(dados)\n",
    "    print(\"-\" * 40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5c0c5ba-4848-45e8-b04c-66823bdc5354",
   "metadata": {},
   "outputs": [],
   "source": [
    "from flask import Flask, request, jsonify\n",
    "from flask_cors import CORS  \n",
    "import os\n",
    "import json\n",
    "\n",
    "app = Flask(__name__)\n",
    "CORS(app)  \n",
    "\n",
    "diretorio = '../modelos_e_resultados/'\n",
    "resultados_modelos = {}\n",
    "\n",
    "for nome_pasta in os.listdir(diretorio):\n",
    "    caminho_pasta = os.path.join(diretorio, nome_pasta)\n",
    "    if os.path.isdir(caminho_pasta):\n",
    "        caminho_json = os.path.join(caminho_pasta, 'resultados.json')\n",
    "        if os.path.exists(caminho_json):\n",
    "            with open(caminho_json, 'r') as arquivo:\n",
    "                resultados_modelos[nome_pasta] = json.load(arquivo)\n",
    "\n",
    "@app.route('/prever', methods=['GET'])\n",
    "def prever():\n",
    "    nome = request.args.get('nome')\n",
    "    if not nome:\n",
    "        return jsonify({\"error\": \"Nome não fornecido\"}), 400\n",
    "    resultado = preveEmTodosModelos(nome)\n",
    "    return jsonify(resultado)\n",
    "\n",
    "@app.route('/buscar', methods=['GET'])\n",
    "def buscar():\n",
    "    nome = request.args.get('nome')\n",
    "    if not nome:\n",
    "        return jsonify({\"error\": \"Nome não fornecido\"}), 400\n",
    "    resultado = busca_no_dataframe(nome)\n",
    "    return jsonify(resultado)\n",
    "\n",
    "@app.route('/resultados', methods=['GET'])\n",
    "def resultados():\n",
    "    return jsonify(resultados_modelos)\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    app.run(debug=True, use_reloader=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f35cf7c2-3e86-4bed-afda-6682db00b2e2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
